# Project Development Prompts & Architecture

## 1. Project Structure

```
AIIS-HW5/
â”œâ”€â”€ .env                        # Environment variables (API Keys, Config)
â”œâ”€â”€ docker-compose.yml          # Docker composition for Backend, Frontend, DB
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile              # Backend image definition
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ main.py                 # FastAPI application & endpoints
â”‚   â”œâ”€â”€ models.py               # SQLAlchemy database models
â”‚   â”œâ”€â”€ database.py             # Database connection setup
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ llm_client.py       # Unified LLM provider client (OpenRouter, Google, etc.)
â”‚       â”œâ”€â”€ rag_engine.py       # RAG core logic (Query, Retrieval, Answer)
â”‚       â”œâ”€â”€ document_processor.py # File reading and parsing
â”‚       â”œâ”€â”€ embedding_service.py  # Vector embedding generation
â”‚       â””â”€â”€ ai_extractor.py     # Metadata extraction
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile              # Frontend image definition
â”‚   â””â”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ data/                       # Persistent database storage (Docker volume)
â””â”€â”€ ARCHIVE_*.md                # Development change logs
```

## 2. Development Interaction Log (Prompts)

### Phase 1: Docker Deployment & connectivity
**User Request:**
> "I cannot connect to the backend from the frontend in Docker."

**Prompt/Action:**
- Analyzed `docker-compose.yml` and `app.py`.
- Identified that `localhost` in Docker refers to the container itself, not the host.
- Updated `API_BASE_URL` to use the service name `http://docdb_backend:8000`.
- Ensured all environment variables (`OPENROUTER_API_KEY`, etc.) are passed from host `.env` to containers.

### Phase 2: RAG Optimization & Authorization
**User Request:**
> "API Key Error: Incorrect API key provided" and "401 Unauthorized"

**Prompt/Action:**
- Debugged `rag_engine.py` which was incorrectly initializing `OpenAI()` client directly.
- Refactored `rag_engine.py` to use the custom `UniversalLLMClient` (`llm_client.py`).
- This ensured the correct `OPENROUTER_API_KEY` and base URL were used instead of defaulting to OpenAI's servers.

### Phase 3: UI & Output Localization
**User Request:**
> "Fix newline characters in UI" and "Enforce Traditional Chinese responses"

**Prompt/Action:**
- Frontend: Replaced literal `\\n` strings with actual newlines in `app.py`.
- Backend: Updated the System Prompt in `rag_engine.py` to explicitly instruct the LLM: "ALWAYS answer in Traditional Chinese (ç¹é«”ä¸­æ–‡)".

### Phase 4: Displaying Original Filenames
**User Request:**
> "Search results show UUIDs (9ed4ab...). Change to original filenames and add open link."

**Prompt/Action:**
- Modified `rag_engine.py` to fetch `original_filename` from the database using the UUID.
- Updated `_format_sources` to return both `document_id` and `filename`.
- Added new endpoint `GET /api/documents/{id}/content`.
- Frontend: Updated source display to show filename (`æ™ºæ…§å»ºç¯‰...pdf`) and added `[ðŸ“¥ é–‹å•Ÿæª”æ¡ˆ]` link.

### Phase 5: Admin Features & Token Limits
**User Request:**
> "Add Admin API, Token Limit, and System configuration."

**Prompt/Action:**
- Created `SystemConfig` model in `models.py`.
- Added `GET/POST /api/admin/config` endpoints.
- Frontend: Added "âš™ï¸ ç³»çµ±è¨­å®š" tab in Admin page.
- Implemented UI for setting "Daily Token Limit" and visualizing usage.

### Phase 6: Robustness (Upload Check & Rate Limits)
**User Request:**
> "Prevent duplicate uploads" and "Fix 429 Too Many Requests"

**Prompt/Action:**
- Backend: Added check in `upload_document` for existing filename + size. Returns `409 Conflict`.
- Backend: Added retry logic (Exponential Backoff) in `llm_client.py` for OpenRouter 429 errors.
- Frontend: Increased upload timeout to 120s to prevent client-side timeouts.

---
**This log captures the iterative development process from basic containerization to a refined, robust RAG application.**
